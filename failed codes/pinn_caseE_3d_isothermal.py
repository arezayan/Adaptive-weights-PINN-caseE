# -*- coding: utf-8 -*-
"""PINN_CaseE_3D_isoThermal.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pBjWPyWPt0zf7w5k5a9872lzqXBCfz85

## **Import Libraries**
"""

# -*- coding: utf-8 -*-
"""
Created on Wed Aug 14 09:57:07 2024
case E- AIJ group
@author: Amirreza
"""

import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import time

# Check if CUDA is available
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

"""# **Define Network | Physics-informed**"""

class PINN(nn.Module):
    def __init__(self, layers):
        super(PINN, self).__init__()
        self.layers = nn.ModuleList()

        for i in range(len(layers) - 1):
            layer = nn.Linear(layers[i], layers[i + 1])
            nn.init.xavier_uniform_(layer.weight)  # Xavier initialization for weights
            nn.init.zeros_(layer.bias)             # Initialize biases to zero
            self.layers.append(layer)

    def forward(self, x):
        for i in range(len(self.layers) - 1):
            x = torch.tanh(self.layers[i](x))
        x = self.layers[-1](x)
        return x

# Define the network architecture
#layers = [3,  40, 40, 40, 40, 40, 40, 40, 40,  4]  # Input: (x, y), Output: (u, v, p)
num_hide = 40
layers = [3, num_hide, num_hide, num_hide, num_hide, num_hide, num_hide, num_hide, 4]  # Input: (x, y), Output: (u, v, p)
model = PINN(layers).to(device)

"""# **Define Desired PDE**"""

def navier_stokes_loss(model, x, y, z, mu):
    x = x.requires_grad_(True)
    y = y.requires_grad_(True)
    z = z.requires_grad_(True)

    uvp = model(torch.cat((x, y, z), dim=1))
    u = uvp[:, 0:1]
    v = uvp[:, 1:2]
    w = uvp[:, 2:3]
    p = uvp[:, 3:4]

    # Calculate gradients
    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]
    u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]
    u_z = torch.autograd.grad(u, z, grad_outputs=torch.ones_like(u), create_graph=True)[0]

    v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]
    v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(v), create_graph=True)[0]
    v_z = torch.autograd.grad(v, z, grad_outputs=torch.ones_like(v), create_graph=True)[0]

    w_x = torch.autograd.grad(w, x, grad_outputs=torch.ones_like(w), create_graph=True)[0]
    w_y = torch.autograd.grad(w, y, grad_outputs=torch.ones_like(w), create_graph=True)[0]
    w_z = torch.autograd.grad(w, z, grad_outputs=torch.ones_like(w), create_graph=True)[0]

    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]
    u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]
    u_zz = torch.autograd.grad(u_z, z, grad_outputs=torch.ones_like(u_z), create_graph=True)[0]

    v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]
    v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=True)[0]
    v_zz = torch.autograd.grad(v_z, z, grad_outputs=torch.ones_like(v_z), create_graph=True)[0]

    w_xx = torch.autograd.grad(w_x, x, grad_outputs=torch.ones_like(w_x), create_graph=True)[0]
    w_yy = torch.autograd.grad(w_y, y, grad_outputs=torch.ones_like(w_y), create_graph=True)[0]
    w_zz = torch.autograd.grad(w_z, z, grad_outputs=torch.ones_like(w_z), create_graph=True)[0]

    p_x = torch.autograd.grad(p, x, grad_outputs=torch.ones_like(p), create_graph=True)[0]
    p_y = torch.autograd.grad(p, y, grad_outputs=torch.ones_like(p), create_graph=True)[0]
    p_z = torch.autograd.grad(p, z, grad_outputs=torch.ones_like(p), create_graph=True)[0]

    # Navier-Stokes equations

    f_u = u*u_x + v*u_y + w*u_z + p_x - mu * (u_xx + u_yy + u_zz)
    f_v = u*v_x + v*v_y + w*v_z + p_y - mu * (v_xx + v_yy + v_zz)
    f_w = u*w_x + v*w_y + w*w_z + p_z - mu * (w_xx + w_yy + w_zz)

    # Continuity equation
    continuity = u_x + v_y + w_z

    # Loss calculation with balancing factors
    loss_momentum =  (torch.mean(f_u**2) + torch.mean(f_v**2)+ torch.mean(f_w**2))
    loss_continuity = torch.mean(continuity**2)
    return loss_momentum , loss_continuity

def boundary_condition_loss(model, x_b, y_b, z_b, u_b, v_b, w_b, p_b=None):
    uvp_b = model(torch.cat((x_b, y_b, z_b), dim=1))
    u_b_pred = uvp_b[:, 0:1]
    v_b_pred = uvp_b[:, 1:2]
    w_b_pred = uvp_b[:, 2:3]
    p_b_pred = uvp_b[:, 3:4]

    loss_u_b = torch.mean((u_b_pred - u_b) ** 2)
    loss_v_b = torch.mean((v_b_pred - v_b) ** 2)
    loss_w_b = torch.mean((w_b_pred - w_b) ** 2)
    loss_p_b = torch.mean((p_b_pred - p_b) ** 2)

    return loss_u_b + loss_v_b + loss_w_b #+ loss_p_b

def data_loss(model,x,y,z, u_exact, v_exact, w_exact, p_exact=None):
    uvp_pred = model(torch.cat((x, y, z), dim=1))
    u_pred = uvp_pred[:, 0:1]
    v_pred = uvp_pred[:, 1:2]
    w_pred = uvp_pred[:, 2:3]
    p_pred = uvp_pred[:, 3:4] if p_exact is not None else None

    loss_u = torch.mean((u_pred - u_exact) ** 2)
    loss_v = torch.mean((v_pred - v_exact) ** 2)
    loss_w = torch.mean((w_pred - w_exact) ** 2)
    loss_p = torch.mean((p_pred - p_exact) ** 2) if p_exact is not None else 0

    return loss_u + loss_v + loss_w + (loss_p if p_exact is not None else 0)



def total_loss(model, x, y, z, u_exact, v_exact,w_exact,p_exact,
               mu, x_b , y_b, z_b, u_b, v_b, w_b,p_b,
               weight_momentum,weight_continuity , loss_data ,lambda_bc):
    
    

    # Physics-informed loss
    mom_loss, cont_loss = navier_stokes_loss(model, x, y, z, mu)
    momentum_loss  = mom_loss * weight_momentum
    continuity_loss  = cont_loss * weight_continuity
    
    # Data loss
    
    loss_data = data_loss(model, x, y, z, u_exact, v_exact, w_exact, p_exact) * lambda_data

    # Boundary condition loss
    loss_bc = boundary_condition_loss(model, x_b, y_b,z_b, u_b, v_b,w_b, p_b) * lambda_bc if x_b is not None else 0
    loss = momentum_loss + continuity_loss + loss_data + loss_bc

    return loss, momentum_loss , continuity_loss , loss_data , loss_bc

# Load data from CSV
bound = 65 # number of samples coorporated in traing 
data = pd.read_csv('CaseE\caseE_Data.csv')
data = (data - data.min()) / (data.max() - data.min())
data['z'] = 2
data['v'] = data['w'] = 0
x = torch.tensor(data[['x']][:bound].values, dtype=torch.float32).to(device)
y = torch.tensor(data[['y']][:bound].values, dtype=torch.float32).to(device)
z = torch.tensor(data[['z']][:bound].values, dtype=torch.float32).to(device)
u_exact = torch.tensor(data[['u']][:bound].values, dtype=torch.float32).to(device)
v_exact = torch.tensor(data[['v']][:bound].values, dtype=torch.float32).to(device)
w_exact = torch.tensor(data[['w']][:bound].values, dtype=torch.float32).to(device)
p_exact = torch.tensor(data[['p']][:bound].values, dtype=torch.float32).to(device) if 'p' in data.columns else None



# Example boundary data (you may need to replace this with actual data)

bc_data = pd.read_csv('CaseE\caseE_BC.csv')
bc_data = (bc_data - bc_data.min()) / (bc_data.max() - bc_data.min())
bc_data['u'] = bc_data['v'] = bc_data['w'] = 0
x_b = (torch.tensor(bc_data['x'], dtype=torch.float32).to(device)).reshape(-1,1)
y_b = (torch.tensor(bc_data['y'], dtype=torch.float32).to(device)).reshape(-1,1)
z_b = (torch.tensor(bc_data['z'], dtype=torch.float32).to(device)).reshape(-1,1)
u_b = (torch.tensor(bc_data['u'], dtype=torch.float32).to(device)).reshape(-1,1)  # Boundary u-values
v_b = (torch.tensor(bc_data['v'], dtype=torch.float32).to(device)).reshape(-1,1)  # Boundary v-values
w_b = (torch.tensor(bc_data['w'], dtype=torch.float32).to(device)).reshape(-1,1)  # Boundary w-values
p_b = (torch.tensor(bc_data['p'], dtype=torch.float32).to(device)).reshape(-1,1)  # Boundary w-values

"""# **Train with LBGFS optimizers**"""

### LBGFS optimizers
"""
# Training parameters
epochs = 25000
mu = 0.01  # Dynamic viscosity
lambda_momentum = 0.5
lambda_continuity = 0.5
lambda_data = 1
lambda_bc = 1

# Define the optimizer
optimizer = optim.LBFGS(model.parameters(), lr=0.01)#, max_iter=500, history_size=10)

for epoch in range(epochs):
    model.train()

    def closure():
        optimizer.zero_grad()
        loss = total_loss(model, x, y, z, u_exact, v_exact, w_exact, p_exact, mu, x_b, y_b, z_b, u_b, v_b, w_b, p_b,
                          lambda_momentum, lambda_continuity, lambda_data, lambda_bc)
        loss.backward()
        return loss  # Return the loss for the optimizer to use

    loss = optimizer.step(closure)  # The optimizer calls closure and gets the loss

    if epoch % 100 == 0:
        print(f'Epoch {epoch}, Total Loss: {loss.item()}')
        #print(time.time())

model.eval()
with torch.no_grad():
    uvp_pred = model(torch.cat((x, y, z), dim=1))
    u_pred = uvp_pred[:, 0:1]
    v_pred = uvp_pred[:, 1:2]
    w_pred = uvp_pred[:, 2:3]
    p_pred = uvp_pred[:, 3:4]
    
    
#Dynamic Weight calculation

def compute_w_data(x,y,z):
  up= netu(torch.cat((x, y, z), dim=1))
  vp= netv(torch.cat((x, y, z), dim=1))
  wp= netw(torch.cat((x, y, z), dim=1))



  ku =(up - u_exact) / (u_exact + 1e-16)
  kv =(vp - v_exact) / (v_exact + 1e-16)
  kw =(wp - w_exact) / (w_exact + 1e-16)


  ku_mean = torch.mean(ku)
  kv_mean = torch.mean(kv)
  kw_mean = torch.mean(kw)


  wu = (torch.mean(ku) / min(kv_mean , kw_mean) ) **2
  wv = (torch.mean(kv) / min(ku_mean , kw_mean) ) **2
  ww = (torch.mean(kw) / min(ku_mean , kv_mean) ) **2


  return wu,wv, ww


def compute_weight_PDE(momentum_loss , continuity_loss , loss_k , loss_epsilon, prev_mom = torch.tensor(1E11, requires_grad=False), prev_cont = torch.tensor(1E11, requires_grad=False), prev_k = torch.tensor(1E11, requires_grad=False) , prev_epsilon = torch.tensor(1E11, requires_grad=False)):
    # Calculate the magnitude of gradients or loss values and adjust the weights
    weight_momentum = torch.mean(prev_mom) / (torch.mean(momentum_loss) + 1e-8)
    weight_continuity = torch.mean(prev_cont) / (torch.mean(continuity_loss) + 1e-8)
    weight_k = torch.mean(prev_k) / (torch.mean(loss_k) + 1e-8)
    weight_epsilon = torch.mean(prev_epsilon) / (torch.mean(loss_epsilon) + 1e-8)

    # Normalize the weights
    total_weight = weight_momentum + weight_continuity + weight_k + weight_epsilon
    weight_momentum /= total_weight
    weight_continuity /= total_weight
    weight_k /= total_weight
    weight_epsilon /= total_weight

    return weight_momentum, weight_continuity , weight_k , weight_epsilon
    

"""
# Training parameters
epochs = 1500
mu = 1E-5/1.225  # Dynamic viscosity
weight_momentum = 1
weight_continuity = 1
lambda_data = 1
lambda_bc = 1

# Define the optimizer
optimizer = optim.Adam(model.parameters(), lr=1e-4)

for epochs in range(epochs):
    model.train()
    optimizer.zero_grad()

    loss, momentum_loss , continuity_loss , loss_data , loss_bc = total_loss(model, x, y, z, u_exact, v_exact,w_exact,p_exact,
               mu, x_b , y_b, z_b, u_b, v_b, w_b,p_b,
               weight_momentum,weight_continuity ,  lambda_bc,lambda_bc)
    loss.backward()
    optimizer.step()
    ml = momentum_loss.detach().numpy()
    cl = continuity_loss.detach().numpy()
    ld = loss_data.detach().numpy()
    lb = loss_bc.detach().numpy()
    

    if epochs % 1000 == 0:
        
        loss_dic = {"momentum_loss":ml ,
                    "continuity_loss":cl ,
                    "loss_data":ld ,
                    "loss_bc":lb}
        key_max = max(zip(loss_dic.values() , loss_dic.keys()))[1]
        val_max = max(list(loss_dic.values()))
        
        print(f'Epoch {epochs}, Total Loss: {loss.item():.6f}')
        print(f"The Highest loss is for {key_max} :  {val_max:.4f}")
        
        

model.eval()
with torch.no_grad():
    uvp_pred = model(torch.cat((x, y, z), dim=1))
    u_pred = uvp_pred[:, 0:1]
    v_pred = uvp_pred[:, 1:2]
    w_pred = uvp_pred[:, 2:3]
    p_pred = uvp_pred[:, 3:4]

# Convert tensors to numpy arrays
x_train_np = x.cpu().detach().numpy()
y_train_np = y.cpu().detach().numpy()
z_train_np = z.cpu().detach().numpy()
u_exact_np = u_exact.cpu().detach().numpy()
v_exact_np = v_exact.cpu().detach().numpy()
w_exact_np = w_exact.cpu().detach().numpy()
p_exact_np = p_exact.cpu().detach().numpy()

uvp_pred = model(torch.cat((x, y, z), dim=1))
u_pred = uvp_pred[:, 0:1]
v_pred = uvp_pred[:, 1:2]
w_pred = uvp_pred[:, 2:3]
p_pred = uvp_pred[:, 3:4] if p_exact is not None else None

u_pred_np = u_pred.cpu().detach().numpy()
v_pred_np = v_pred.cpu().detach().numpy()
w_pred_np = w_pred.cpu().detach().numpy()
p_pred_np = p_pred.cpu().detach().numpy()

plt.figure(dpi = 150)
plt.plot(u_exact_np, label='Exact u', marker='o')
plt.plot(u_pred_np, label='Predicted u', marker='x')
plt.legend()
plt.title('Comparison of u component')


# Plotting the results
plt.figure(figsize=(20, 5))

plt.subplot(1, 3, 1)
plt.scatter(x_train_np, y_train_np, c=u_exact_np, label='Exact u', marker='o')
plt.plot(u_pred_np, label='Predicted u', marker='x')
plt.legend()
plt.colorbar()
plt.title('Comparison of u component')

plt.subplot(1, 3, 2)
plt.scatter(x_train_np, y_train_np, c=v_exact_np, label='Exact v', marker='o')
plt.plot(v_pred_np, label='Predicted v', marker='x')
plt.legend()
plt.colorbar()
plt.title('Comparison of v component')

plt.subplot(1, 3, 3)
plt.scatter(x_train_np, y_train_np, c=p_exact_np, label='Exact p', marker='o')
plt.plot(p_pred_np, label='Predicted p', marker='x')
plt.legend()
plt.colorbar()
plt.title('Predicted Pressure')



plt.show()

"""# **Test with new Data**"""

x_test = torch.tensor(data[['x']][bound:].values, dtype=torch.float32).to(device)
y_test = torch.tensor(data[['y']][bound:].values, dtype=torch.float32).to(device)
z_test = torch.tensor(data[['z']][bound:].values, dtype=torch.float32).to(device)
u_test = torch.tensor(data[['u']][bound:].values, dtype=torch.float32).to(device)
v_test = torch.tensor(data[['v']][bound:].values, dtype=torch.float32).to(device)
w_test = torch.tensor(data[['w']][bound:].values, dtype=torch.float32).to(device)
p_test = torch.tensor(data[['p']][bound:].values, dtype=torch.float32).to(device)

uvp_test = model(torch.cat((x_test, y_test, z_test), dim=1))
ut_pred = uvp_test[:,0:1]

ut_pred = ut_pred.cpu().detach().numpy()
plt.plot(u_test.cpu(), label = "Exact")
plt.plot(ut_pred, label = "PINN")
#plt.ylim(0.2,0.8)
plt.legend()
x_test.shape


xx = (torch.tensor(data[['x']].values, dtype=torch.float32)).reshape(-1,1)
yy = (torch.tensor(data[['y']].values, dtype=torch.float32)).reshape(-1,1)
zz = (torch.tensor(data[['z']].values, dtype=torch.float32)).reshape(-1,1)

uu = (torch.tensor(data[['u']].values, dtype=torch.float32)).reshape(-1,1)

uvwp_test = model(torch.cat((xx, yy, zz), dim=1))
up = uvwp_test[:,0:1]


plt.subplots(1,1)
plt.title("Exact")
plt.tricontourf(xx.flatten(), yy.flatten(), uu.flatten(), cmap="RdBu_r")
plt.colorbar()

plt.subplots(1,2)
plt.title("PINN")
plt.tricontourf(xx.flatten(),yy.flatten(),up.detach().numpy().flatten(), cmap="RdBu_r")
plt.colorbar()
plt.show()

